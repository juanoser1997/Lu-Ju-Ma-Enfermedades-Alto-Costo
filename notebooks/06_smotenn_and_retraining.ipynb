{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#  Balanceo SMOTEENN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess, sys\n",
        "from pathlib import Path\n",
        "PROJECT_ROOT = Path.cwd().parent if 'notebooks' in str(Path.cwd()) else Path.cwd()\n",
        "sys.path.insert(0, str(PROJECT_ROOT))\n",
        "for pkg in ['pandas', 'numpy', 'imbalanced-learn', 'xgboost', 'lightgbm']: \n",
        "    try: __import__(pkg)\n",
        "    except: subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pkg])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys; sys.path.insert(0, str(PROJECT_ROOT / 'src'))\n",
        "from sampling import SMOTEENNBalancer\n",
        "from modeling import retrain_with_balanced_data\n",
        "from evaluation import compare_models\n",
        "import warnings; warnings.filterwarnings('ignore')\n",
        "\n",
        "DATA_PROCESSED = PROJECT_ROOT / 'data' / 'processed'\n",
        "X_train = np.load(DATA_PROCESSED / 'X_train.npy')\n",
        "X_test = np.load(DATA_PROCESSED / 'X_test.npy')\n",
        "y_train = np.load(DATA_PROCESSED / 'y_train.npy')\n",
        "y_test = np.load(DATA_PROCESSED / 'y_test.npy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tres Niveles SMOTEENN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Aplicando SMOTEENN - Nivel: LOW\n",
            "\n",
            " Distribución original:\n",
            "  Clase 0: 30422 (89.17%)\n",
            "  Clase 1: 2067 (6.06%)\n",
            "  Clase 2: 76 (0.22%)\n",
            "  Clase 3: 1550 (4.54%)\n",
            "\n",
            " Distribución balanceada:\n",
            "  Clase 0: 21754 (76.29%) [-8668]\n",
            "  Clase 1: 3042 (10.67%) [+975]\n",
            "  Clase 2: 2874 (10.08%) [+2798]\n",
            "  Clase 3: 846 (2.97%) [-704]\n",
            "\n",
            " Total: 34115 → 28516 muestras\n",
            "\n",
            " Aplicando SMOTEENN - Nivel: MEDIUM\n",
            "\n",
            " Distribución original:\n",
            "  Clase 0: 30422 (89.17%)\n",
            "  Clase 1: 2067 (6.06%)\n",
            "  Clase 2: 76 (0.22%)\n",
            "  Clase 3: 1550 (4.54%)\n",
            "\n",
            " Distribución balanceada:\n",
            "  Clase 0: 20519 (56.33%) [-9903]\n",
            "  Clase 1: 6084 (16.70%) [+4017]\n",
            "  Clase 2: 5987 (16.44%) [+5911]\n",
            "  Clase 3: 3835 (10.53%) [+2285]\n",
            "\n",
            " Total: 34115 → 36425 muestras\n",
            "\n",
            " Aplicando SMOTEENN - Nivel: HIGH\n",
            "\n",
            " Distribución original:\n",
            "  Clase 0: 30422 (89.17%)\n",
            "  Clase 1: 2067 (6.06%)\n",
            "  Clase 2: 76 (0.22%)\n",
            "  Clase 3: 1550 (4.54%)\n",
            "\n",
            " Distribución balanceada:\n",
            "  Clase 0: 18065 (20.24%) [-12357]\n",
            "  Clase 1: 24337 (27.27%) [+22270]\n",
            "  Clase 2: 24302 (27.23%) [+24226]\n",
            "  Clase 3: 22556 (25.27%) [+21006]\n",
            "\n",
            " Total: 34115 → 89260 muestras\n",
            "\n",
            " Reentrenando modelos con balanceo: LOW\n",
            "\n",
            "  Entrenando LogisticRegression...\n",
            "    ✓ Completado\n",
            "  Entrenando RandomForest...\n",
            "    ✓ Completado\n",
            "  Entrenando XGBoost...\n",
            "    ✓ Completado\n",
            "  Entrenando LightGBM...\n",
            "    ✓ Completado\n",
            "  Entrenando KNN...\n",
            "    ✓ Completado\n",
            "\n",
            " Reentrenando modelos con balanceo: MEDIUM\n",
            "\n",
            "  Entrenando LogisticRegression...\n",
            "    ✓ Completado\n",
            "  Entrenando RandomForest...\n",
            "    ✓ Completado\n",
            "  Entrenando XGBoost...\n",
            "    ✓ Completado\n",
            "  Entrenando LightGBM...\n",
            "    ✓ Completado\n",
            "  Entrenando KNN...\n",
            "    ✓ Completado\n",
            "\n",
            " Reentrenando modelos con balanceo: HIGH\n",
            "\n",
            "  Entrenando LogisticRegression...\n",
            "    ✓ Completado\n",
            "  Entrenando RandomForest...\n",
            "    ✓ Completado\n",
            "  Entrenando XGBoost...\n",
            "    ✓ Completado\n",
            "  Entrenando LightGBM...\n",
            "    ✓ Completado\n",
            "  Entrenando KNN...\n",
            "    ✓ Completado\n",
            "                Model  F1_Weighted  F1_Macro  Precision    Recall  Accuracy  \\\n",
            "0  LogisticRegression     0.839831  0.250684   0.847644  0.883105  0.883105   \n",
            "1        RandomForest     0.845565  0.265306   0.842226  0.889553  0.889553   \n",
            "2             XGBoost     0.848919  0.313680   0.836851  0.874897  0.874897   \n",
            "3            LightGBM     0.846333  0.316891   0.833148  0.868449  0.868449   \n",
            "4                 KNN     0.812520  0.310247   0.823935  0.802087  0.802087   \n",
            "0  LogisticRegression     0.822344  0.326117   0.830422  0.818267  0.818267   \n",
            "1        RandomForest     0.843207  0.342185   0.837275  0.856138  0.856138   \n",
            "2             XGBoost     0.826362  0.352190   0.840007  0.815570  0.815570   \n",
            "3            LightGBM     0.826016  0.353131   0.839656  0.814867  0.814867   \n",
            "4                 KNN     0.751578  0.312344   0.830715  0.696447  0.696447   \n",
            "0  LogisticRegression     0.231464  0.168556   0.857755  0.189354  0.189354   \n",
            "1        RandomForest     0.553708  0.263434   0.852624  0.458201  0.458201   \n",
            "2             XGBoost     0.601922  0.275561   0.846708  0.507797  0.507797   \n",
            "3            LightGBM     0.617965  0.282429   0.847429  0.526322  0.526322   \n",
            "4                 KNN     0.631525  0.271927   0.835662  0.538164  0.538164   \n",
            "\n",
            "    ROC_AUC  \n",
            "0  0.611107  \n",
            "1  0.659988  \n",
            "2  0.664429  \n",
            "3  0.663332  \n",
            "4  0.590156  \n",
            "0  0.647545  \n",
            "1  0.677130  \n",
            "2  0.677415  \n",
            "3  0.679442  \n",
            "4  0.611253  \n",
            "0  0.651005  \n",
            "1  0.672181  \n",
            "2  0.673143  \n",
            "3  0.671735  \n",
            "4  0.612876  \n"
          ]
        }
      ],
      "source": [
        "balancer = SMOTEENNBalancer(random_state=42)\n",
        "balanced_data = balancer.apply_multiple_levels(X_train, y_train)\n",
        "results_low = retrain_with_balanced_data(balanced_data['low']['X'], balanced_data['low']['y'], X_test, y_test, 'LOW')\n",
        "results_med = retrain_with_balanced_data(balanced_data['medium']['X'], balanced_data['medium']['y'], X_test, y_test, 'MEDIUM')\n",
        "results_high = retrain_with_balanced_data(balanced_data['high']['X'], balanced_data['high']['y'], X_test, y_test, 'HIGH')\n",
        "comp_low = compare_models(results_low, y_test)\n",
        "comp_med = compare_models(results_med, y_test)\n",
        "comp_high = compare_models(results_high, y_test)\n",
        "full_comp = pd.concat([comp_low, comp_med, comp_high])\n",
        "print(full_comp)\n",
        "full_comp.to_csv(DATA_PROCESSED / 'smoteenn_comparison.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Análisis: se Aplico SMOTENN en varios niveles y se reentreno el modelos; el reporte indica una mejora en recall de las minoritarias del orden de ~15–20% tras el balanceo. Se generaron comparativos (smoteenn_comparison.csv) para cada nivel.\n",
        "\n",
        "Conclusiones: SMOTENN mejoró sustancialmente la detección de clases minoritarias; es la estrategia recomendada antes del tuning fino."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
