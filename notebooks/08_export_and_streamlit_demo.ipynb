{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#  Exportación y Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess, sys\n",
        "from pathlib import Path\n",
        "PROJECT_ROOT = Path.cwd().parent if 'notebooks' in str(Path.cwd()) else Path.cwd()\n",
        "sys.path.insert(0, str(PROJECT_ROOT))\n",
        "for pkg in ['pandas', 'numpy', 'joblib']: \n",
        "    try: __import__(pkg)\n",
        "    except: subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pkg])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Predicciones exportadas a: c:\\Proyecto_Enfermedades_Alto_Costo completo\\Proyecto_Enfermedades_Alto_Costo completo\\data\\processed\\predictions.csv\n",
            "✓ Pipeline cargado desde: c:\\Proyecto_Enfermedades_Alto_Costo completo\\Proyecto_Enfermedades_Alto_Costo completo\\data\\processed\\preprocessor.joblib\n",
            "✓ Modelo y componentes exportados para deployment en: c:\\Proyecto_Enfermedades_Alto_Costo completo\\Proyecto_Enfermedades_Alto_Costo completo\\deployment_package\n",
            "✅ Exportación completada\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import sys; sys.path.insert(0, str(PROJECT_ROOT / 'src'))\n",
        "from export import export_predictions, export_metrics, export_model_for_deployment\n",
        "from preprocessing import PreprocessingPipeline\n",
        "import warnings; warnings.filterwarnings('ignore')\n",
        "\n",
        "DATA_PROCESSED = PROJECT_ROOT / 'data' / 'processed'\n",
        "X_test = np.load(DATA_PROCESSED / 'X_test.npy')\n",
        "y_test = np.load(DATA_PROCESSED / 'y_test.npy')\n",
        "model_data = joblib.load(DATA_PROCESSED / 'best_model.joblib')\n",
        "best_model = model_data['model']\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_pred_proba = best_model.predict_proba(X_test) if hasattr(best_model, 'predict_proba') else None\n",
        "df_predictions = export_predictions(y_test, y_pred, y_pred_proba, output_path=str(DATA_PROCESSED / 'predictions.csv'))\n",
        "preprocessor = PreprocessingPipeline.load(DATA_PROCESSED / 'preprocessor.joblib')\n",
        "deployment_dir = PROJECT_ROOT / 'deployment_package'\n",
        "deployment_dir.mkdir(exist_ok=True)\n",
        "export_model_for_deployment(best_model, preprocessor.pipeline, preprocessor.label_encoder, model_data['metadata'], str(deployment_dir))\n",
        "print(' Exportación completada')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Análisis: Se exporto predicciones, métricas y artefactos (modelo y preprocessor) para despliegue; el notebook indica “ Exportación completada” y que el proyecto finaliza con Modelo F1 > 0.90. Se generan archivos: predictions.csv, preprocessor.joblib y best_model.joblib.\n",
        "\n",
        "Conclusiones: Los artefactos exportados y la demo en Streamlit permiten uso operativo del modelo; la métrica F1 reportada (>0.90) valida la preparación para producción"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
