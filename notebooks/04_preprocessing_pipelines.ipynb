{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#  Pipelines de Preprocesamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess, sys\n",
        "from pathlib import Path\n",
        "PROJECT_ROOT = Path.cwd().parent if 'notebooks' in str(Path.cwd()) else Path.cwd()\n",
        "sys.path.insert(0, str(PROJECT_ROOT))\n",
        "for pkg in ['pandas', 'numpy', 'scikit-learn']: \n",
        "    try: __import__(pkg)\n",
        "    except: subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', pkg])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sys; sys.path.insert(0, str(PROJECT_ROOT / 'src'))\n",
        "from preprocessing import PreprocessingPipeline, compare_pca_components\n",
        "from io_utils import identify_column_types\n",
        "import warnings; warnings.filterwarnings('ignore')\n",
        "\n",
        "DATA_PROCESSED = PROJECT_ROOT / 'data' / 'processed'\n",
        "X = pd.read_parquet(DATA_PROCESSED / 'imputed.parquet')\n",
        "y = pd.read_parquet(DATA_PROCESSED / 'target.parquet')['GRUPO']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pipeline con PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ“Š Probando PCA con 90.0% varianza explicada...\n",
            "  Componentes: 12\n",
            "  Varianza real: 90.68%\n",
            "  F1-Score: 0.8407 (Â±0.0000)\n",
            "\n",
            "ðŸ“Š Probando PCA con 95.0% varianza explicada...\n",
            "  Componentes: 23\n",
            "  Varianza real: 95.04%\n",
            "  F1-Score: 0.8407 (Â±0.0000)\n",
            "\n",
            "ðŸ“Š Probando PCA con 99.0% varianza explicada...\n",
            "  Componentes: 91\n",
            "  Varianza real: 99.01%\n",
            "  F1-Score: 0.8408 (Â±0.0001)\n",
            "   variance_threshold  n_components  actual_variance  f1_score    f1_std  \\\n",
            "0                0.90            12         0.906847  0.840729  0.000043   \n",
            "1                0.95            23         0.950387  0.840729  0.000043   \n",
            "2                0.99            91         0.990125  0.840775  0.000107   \n",
            "\n",
            "   transform_time  eval_time  \n",
            "0        0.884194   9.676269  \n",
            "1        0.432174   7.897848  \n",
            "2        0.787330   9.984867  \n"
          ]
        }
      ],
      "source": [
        "col_types = identify_column_types(X)\n",
        "numeric_cols = col_types['numeric']\n",
        "categorical_cols = col_types['categorical']\n",
        "pca_comparison = compare_pca_components(X, numeric_cols, categorical_cols, y, [0.90, 0.95, 0.99])\n",
        "print(pca_comparison)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Pipeline guardado en: c:\\Proyecto_Enfermedades_Alto_Costo completo\\Proyecto_Enfermedades_Alto_Costo completo\\data\\processed\\preprocessor.joblib\n",
            "âœ… Guardado\n"
          ]
        }
      ],
      "source": [
        "prep = PreprocessingPipeline(numeric_cols, categorical_cols, scaler_type='standard', use_pca=True, pca_variance=0.95)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "X_train_transformed, y_train_encoded = prep.fit_transform(X_train, y_train)\n",
        "X_test_transformed = prep.transform(X_test)\n",
        "y_test_encoded, _ = prep.label_encoder.transform(y_test), None\n",
        "prep.save(DATA_PROCESSED / 'preprocessor.joblib')\n",
        "np.save(DATA_PROCESSED / 'X_train.npy', X_train_transformed)\n",
        "np.save(DATA_PROCESSED / 'X_test.npy', X_test_transformed)\n",
        "np.save(DATA_PROCESSED / 'y_train.npy', y_train_encoded)\n",
        "np.save(DATA_PROCESSED / 'y_test.npy', y_test_encoded)\n",
        "print(' Guardado')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "AnÃ¡lisis: se Implemento pipeline con codificaciÃ³n, escalado y opciÃ³n PCA; para 90% de varianza se requieren 12 componentes (F1 â‰ˆ 0.8407), para 95% 23 componentes (F1 â‰ˆ 0.8408) y para 99% 91 componentes (F1 â‰ˆ 0.8408). Los resultados indican mÃ­nima pÃ©rdida de F1 al reducir dimensionalidad.\n",
        "\n",
        "Conclusiones: El pipeline estandarizado garantiza reproducibilidad; aplicar PCA a 90â€“95% permite reducciÃ³n dimensional sin degradar significativamente F1."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
