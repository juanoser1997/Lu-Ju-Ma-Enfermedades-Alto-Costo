{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 - ENTRENAMIENTO DE MODELOS\n",
    "## Comparaci\u00f3n de M\u00faltiples Algoritmos de Machine Learning\n",
    "\n",
    "---\n",
    "\n",
    "## Objetivo\n",
    "Entrenar y comparar m\u00faltiples modelos de ML para seleccionar el mejor clasificador de enfermedades de alto costo.\n",
    "\n",
    "**IMPORTANTE**: Este notebook maneja correctamente el encoding de variables categ\u00f3ricas para XGBoost.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. IMPORTACI\u00d3N DE LIBRER\u00cdAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Modelos de sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# XGBoost y LightGBM\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# M\u00e9tricas y validaci\u00f3n\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Visualizaci\u00f3n\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print('\u2713 Librer\u00edas importadas correctamente')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CARGA DE DATOS PREPROCESADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos preprocesados del notebook 02\n",
    "X_train = pd.read_csv('X_train_balanced.csv')\n",
    "y_train = pd.read_csv('y_train_balanced.csv').values.ravel()\n",
    "X_test = pd.read_csv('X_test.csv')\n",
    "y_test = pd.read_csv('y_test.csv').values.ravel()\n",
    "\n",
    "print('\u2713 Datos cargados exitosamente')\n",
    "print(f'\\n\ud83d\udcca DIMENSIONES:')\n",
    "print(f'  Train: X={X_train.shape}, y={y_train.shape}')\n",
    "print(f'  Test:  X={X_test.shape}, y={y_test.shape}')\n",
    "\n",
    "print(f'\\n\ud83d\udcca DISTRIBUCI\u00d3N DE CLASES EN TRAIN:')\n",
    "print(pd.Series(y_train).value_counts().sort_index())\n",
    "\n",
    "print(f'\\n\ud83d\udcca DISTRIBUCI\u00d3N DE CLASES EN TEST:')\n",
    "print(pd.Series(y_test).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ENCODING DE LA VARIABLE OBJETIVO (CR\u00cdTICO) \ud83d\udd34\n",
    "\n",
    "**PROBLEMA**: XGBoost, LightGBM y otros algoritmos requieren que la variable objetivo sea num\u00e9rica (0, 1, 2, 3), NO strings ('CANCER', 'VIH', etc.)\n",
    "\n",
    "**SOLUCI\u00d3N**: Usar LabelEncoder para convertir:\n",
    "- CANCER \u2192 0\n",
    "- ER CRONICA \u2192 1  \n",
    "- HEMOFILIA \u2192 2\n",
    "- VIH \u2192 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y ajustar el LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)  # Ajustar con todas las clases del train\n",
    "\n",
    "# Transformar AMBOS conjuntos (train y test)\n",
    "y_train_encoded = label_encoder.transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "print('\u2713 Variable objetivo encodificada correctamente')\n",
    "print('\\n\ud83d\udccb MAPEO DE CLASES:')\n",
    "print('='*50)\n",
    "for i, clase in enumerate(label_encoder.classes_):\n",
    "    print(f'  {i} \u2192 {clase}')\n",
    "\n",
    "print(f'\\n\ud83d\udcca VERIFICACI\u00d3N:')\n",
    "print(f'  y_train_encoded shape: {y_train_encoded.shape}')\n",
    "print(f'  y_train_encoded type: {type(y_train_encoded[0])}')\n",
    "print(f'  Valores \u00fanicos: {np.unique(y_train_encoded)}')\n",
    "\n",
    "# Guardar el encoder para uso futuro\n",
    "with open('label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "print('\\n\u2713 LabelEncoder guardado: label_encoder.pkl')\n",
    "print('  (Necesario para decodificar predicciones en producci\u00f3n)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ENTRENAMIENTO DE MODELOS\n",
    "\n",
    "Entrenaremos 6 modelos diferentes y compararemos su rendimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*80)\n",
    "print('MODELO 1: RANDOM FOREST')\n",
    "print('='*80)\n",
    "\n",
    "# Entrenar\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=15,\n",
    "    min_samples_split=5,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print('\u23f3 Entrenando Random Forest...')\n",
    "rf.fit(X_train, y_train_encoded)\n",
    "print('\u2713 Entrenamiento completado')\n",
    "\n",
    "# Predecir\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# M\u00e9tricas\n",
    "f1_rf = f1_score(y_test_encoded, y_pred_rf, average='macro')\n",
    "f1_weighted_rf = f1_score(y_test_encoded, y_pred_rf, average='weighted')\n",
    "\n",
    "print(f'\\n\ud83d\udcca RESULTADOS:')\n",
    "print(f'  F1-Score Macro:    {f1_rf:.4f}')\n",
    "print(f'  F1-Score Weighted: {f1_weighted_rf:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*80)\n",
    "print('MODELO 2: GRADIENT BOOSTING')\n",
    "print('='*80)\n",
    "\n",
    "# Entrenar\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=150,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print('\u23f3 Entrenando Gradient Boosting...')\n",
    "gb.fit(X_train, y_train_encoded)\n",
    "print('\u2713 Entrenamiento completado')\n",
    "\n",
    "# Predecir\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "\n",
    "# M\u00e9tricas\n",
    "f1_gb = f1_score(y_test_encoded, y_pred_gb, average='macro')\n",
    "f1_weighted_gb = f1_score(y_test_encoded, y_pred_gb, average='weighted')\n",
    "\n",
    "print(f'\\n\ud83d\udcca RESULTADOS:')\n",
    "print(f'  F1-Score Macro:    {f1_gb:.4f}')\n",
    "print(f'  F1-Score Weighted: {f1_weighted_gb:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 XGBoost (\u2b50 RECOMENDADO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*80)\n",
    "print('MODELO 3: XGBOOST')\n",
    "print('='*80)\n",
    "\n",
    "# Entrenar\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=200,\n",
    "    max_depth=7,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "print('\u23f3 Entrenando XGBoost...')\n",
    "xgb_model.fit(X_train, y_train_encoded)\n",
    "print('\u2713 Entrenamiento completado')\n",
    "\n",
    "# Predecir\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# M\u00e9tricas\n",
    "f1_xgb = f1_score(y_test_encoded, y_pred_xgb, average='macro')\n",
    "f1_weighted_xgb = f1_score(y_test_encoded, y_pred_xgb, average='weighted')\n",
    "\n",
    "print(f'\\n\ud83d\udcca RESULTADOS:')\n",
    "print(f'  F1-Score Macro:    {f1_xgb:.4f}')\n",
    "print(f'  F1-Score Weighted: {f1_weighted_xgb:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 LightGBM (\u2b50 RECOMENDADO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*80)\n",
    "print('MODELO 4: LIGHTGBM')\n",
    "print('='*80)\n",
    "\n",
    "# Entrenar\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    num_leaves=31,\n",
    "    learning_rate=0.05,\n",
    "    n_estimators=200,\n",
    "    feature_fraction=0.8,\n",
    "    bagging_fraction=0.8,\n",
    "    bagging_freq=5,\n",
    "    random_state=42,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "print('\u23f3 Entrenando LightGBM...')\n",
    "lgb_model.fit(X_train, y_train_encoded)\n",
    "print('\u2713 Entrenamiento completado')\n",
    "\n",
    "# Predecir\n",
    "y_pred_lgb = lgb_model.predict(X_test)\n",
    "\n",
    "# M\u00e9tricas\n",
    "f1_lgb = f1_score(y_test_encoded, y_pred_lgb, average='macro')\n",
    "f1_weighted_lgb = f1_score(y_test_encoded, y_pred_lgb, average='weighted')\n",
    "\n",
    "print(f'\\n\ud83d\udcca RESULTADOS:')\n",
    "print(f'  F1-Score Macro:    {f1_lgb:.4f}')\n",
    "print(f'  F1-Score Weighted: {f1_weighted_lgb:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*80)\n",
    "print('MODELO 5: SUPPORT VECTOR MACHINE (SVM)')\n",
    "print('='*80)\n",
    "\n",
    "# Entrenar (puede tardar m\u00e1s)\n",
    "svm_model = SVC(\n",
    "    kernel='rbf',\n",
    "    C=10,\n",
    "    gamma='scale',\n",
    "    probability=True,\n",
    "    random_state=42,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print('\u23f3 Entrenando SVM (puede tardar 5-10 minutos)...')\n",
    "svm_model.fit(X_train, y_train_encoded)\n",
    "print('\u2713 Entrenamiento completado')\n",
    "\n",
    "# Predecir\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# M\u00e9tricas\n",
    "f1_svm = f1_score(y_test_encoded, y_pred_svm, average='macro')\n",
    "f1_weighted_svm = f1_score(y_test_encoded, y_pred_svm, average='weighted')\n",
    "\n",
    "print(f'\\n\ud83d\udcca RESULTADOS:')\n",
    "print(f'  F1-Score Macro:    {f1_svm:.4f}')\n",
    "print(f'  F1-Score Weighted: {f1_weighted_svm:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Red Neuronal (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n' + '='*80)\n",
    "print('MODELO 6: RED NEURONAL (MLP)')\n",
    "print('='*80)\n",
    "\n",
    "# Entrenar\n",
    "nn_model = MLPClassifier(\n",
    "    hidden_layer_sizes=(100, 50),\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=500,\n",
    "    early_stopping=True,\n",
    "    random_state=42,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print('\u23f3 Entrenando Red Neuronal...')\n",
    "nn_model.fit(X_train, y_train_encoded)\n",
    "print('\u2713 Entrenamiento completado')\n",
    "\n",
    "# Predecir\n",
    "y_pred_nn = nn_model.predict(X_test)\n",
    "\n",
    "# M\u00e9tricas\n",
    "f1_nn = f1_score(y_test_encoded, y_pred_nn, average='macro')\n",
    "f1_weighted_nn = f1_score(y_test_encoded, y_pred_nn, average='weighted')\n",
    "\n",
    "print(f'\\n\ud83d\udcca RESULTADOS:')\n",
    "print(f'  F1-Score Macro:    {f1_nn:.4f}')\n",
    "print(f'  F1-Score Weighted: {f1_weighted_nn:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. COMPARACI\u00d3N DE MODELOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear DataFrame con resultados\n",
    "resultados = pd.DataFrame({\n",
    "    'Modelo': ['Random Forest', 'Gradient Boosting', 'XGBoost', 'LightGBM', 'SVM', 'Neural Network'],\n",
    "    'F1-Macro': [f1_rf, f1_gb, f1_xgb, f1_lgb, f1_svm, f1_nn],\n",
    "    'F1-Weighted': [f1_weighted_rf, f1_weighted_gb, f1_weighted_xgb, \n",
    "                    f1_weighted_lgb, f1_weighted_svm, f1_weighted_nn]\n",
    "}).sort_values('F1-Macro', ascending=False)\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('COMPARACI\u00d3N DE TODOS LOS MODELOS')\n",
    "print('='*80)\n",
    "print(resultados.to_string(index=False))\n",
    "\n",
    "# Visualizaci\u00f3n\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Gr\u00e1fico 1: F1-Macro\n",
    "axes[0].barh(resultados['Modelo'], resultados['F1-Macro'], color='steelblue')\n",
    "axes[0].set_xlabel('F1-Score Macro', fontweight='bold')\n",
    "axes[0].set_title('Comparaci\u00f3n por F1-Macro', fontweight='bold', fontsize=14)\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Gr\u00e1fico 2: F1-Weighted\n",
    "axes[1].barh(resultados['Modelo'], resultados['F1-Weighted'], color='coral')\n",
    "axes[1].set_xlabel('F1-Score Weighted', fontweight='bold')\n",
    "axes[1].set_title('Comparaci\u00f3n por F1-Weighted', fontweight='bold', fontsize=14)\n",
    "axes[1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. SELECCI\u00d3N DEL MEJOR MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario con todos los modelos\n",
    "modelos_dict = {\n",
    "    'Random Forest': (rf, f1_rf),\n",
    "    'Gradient Boosting': (gb, f1_gb),\n",
    "    'XGBoost': (xgb_model, f1_xgb),\n",
    "    'LightGBM': (lgb_model, f1_lgb),\n",
    "    'SVM': (svm_model, f1_svm),\n",
    "    'Neural Network': (nn_model, f1_nn)\n",
    "}\n",
    "\n",
    "# Seleccionar el mejor\n",
    "best_name = max(modelos_dict, key=lambda x: modelos_dict[x][1])\n",
    "best_model = modelos_dict[best_name][0]\n",
    "best_f1 = modelos_dict[best_name][1]\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('\ud83c\udfc6 MEJOR MODELO SELECCIONADO')\n",
    "print('='*80)\n",
    "print(f'\\n  Modelo: {best_name}')\n",
    "print(f'  F1-Score Macro: {best_f1:.4f}')\n",
    "print('\\n' + '='*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. EVALUACI\u00d3N DETALLADA DEL MEJOR MODELO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones del mejor modelo\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Decodificar para mostrar nombres de clases\n",
    "y_test_decoded = label_encoder.inverse_transform(y_test_encoded)\n",
    "y_pred_decoded = label_encoder.inverse_transform(y_pred_best)\n",
    "\n",
    "# Reporte de clasificaci\u00f3n\n",
    "print('\\n' + '='*80)\n",
    "print(f'REPORTE DE CLASIFICACI\u00d3N - {best_name}')\n",
    "print('='*80)\n",
    "print(classification_report(y_test_decoded, y_pred_decoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. MATRIZ DE CONFUSI\u00d3N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusi\u00f3n\n",
    "cm = confusion_matrix(y_test_decoded, y_pred_decoded, labels=label_encoder.classes_)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=label_encoder.classes_,\n",
    "            yticklabels=label_encoder.classes_,\n",
    "            cbar_kws={'label': 'N\u00famero de casos'})\n",
    "plt.title(f'Matriz de Confusi\u00f3n - {best_name}', fontweight='bold', fontsize=14, pad=15)\n",
    "plt.ylabel('Clase Real', fontweight='bold')\n",
    "plt.xlabel('Clase Predicha', fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# An\u00e1lisis de la matriz\n",
    "print('\\n\ud83d\udca1 INTERPRETACI\u00d3N DE LA MATRIZ:')\n",
    "print('  - Diagonal: Predicciones correctas')\n",
    "print('  - Fuera de diagonal: Confusiones entre clases')\n",
    "print('  - Observar qu\u00e9 clases se confunden m\u00e1s entre s\u00ed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. GUARDAR MODELO FINAL Y ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar mejor modelo\n",
    "with open('modelo_final.pkl', 'wb') as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "# Ya guardamos el encoder anteriormente, pero reconfirmamos\n",
    "with open('label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "\n",
    "print('\\n' + '='*80)\n",
    "print('\u2705 ARCHIVOS GUARDADOS')\n",
    "print('='*80)\n",
    "print('\\n  1. modelo_final.pkl      \u2192 Mejor modelo entrenado')\n",
    "print('  2. label_encoder.pkl     \u2192 Encoder para decodificar predicciones')\n",
    "\n",
    "print('\\n\ud83d\udca1 USO EN PRODUCCI\u00d3N:')\n",
    "print('  # Cargar modelo')\n",
    "print('  with open(\"modelo_final.pkl\", \"rb\") as f:')\n",
    "print('      modelo = pickle.load(f)')\n",
    "print('  ')\n",
    "print('  # Cargar encoder')\n",
    "print('  with open(\"label_encoder.pkl\", \"rb\") as f:')\n",
    "print('      encoder = pickle.load(f)')\n",
    "print('  ')\n",
    "print('  # Predecir')\n",
    "print('  pred_encoded = modelo.predict(X_new)')\n",
    "print('  pred_decoded = encoder.inverse_transform(pred_encoded)')\n",
    "print('  # pred_decoded contendr\u00e1 los nombres: \"CANCER\", \"VIH\", etc.')\n",
    "\n",
    "print('\\n' + '='*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. RESUMEN Y CONCLUSIONES\n",
    "\n",
    "---\n",
    "\n",
    "### \u2705 Logros:\n",
    "1. Entrenamiento exitoso de 6 modelos diferentes\n",
    "2. Comparaci\u00f3n objetiva con m\u00e9tricas balanceadas\n",
    "3. Selecci\u00f3n del mejor modelo basado en F1-Score macro\n",
    "4. Evaluaci\u00f3n detallada con matriz de confusi\u00f3n\n",
    "5. Modelo guardado y listo para producci\u00f3n\n",
    "\n",
    "### \ud83d\udcca Resultados Esperados:\n",
    "- **F1-Score Macro**: > 0.75 (balance entre todas las clases)\n",
    "- **F1-Score Weighted**: > 0.80 (considerando distribuci\u00f3n real)\n",
    "- **Recall por clase**: Idealmente > 0.70 para cada enfermedad\n",
    "\n",
    "### \ud83c\udfaf Mejor Modelo:\n",
    "- T\u00edpicamente XGBoost o LightGBM obtienen los mejores resultados\n",
    "- Buen balance entre velocidad y precisi\u00f3n\n",
    "- Interpretable con feature importance\n",
    "\n",
    "### \u26a0\ufe0f Consideraciones Importantes:\n",
    "1. **LabelEncoder es CR\u00cdTICO**: Sin \u00e9l, XGBoost y LightGBM fallan\n",
    "2. **Guardar el encoder**: Necesario para decodificar predicciones\n",
    "3. **Test set sin balancear**: Refleja la distribuci\u00f3n real\n",
    "4. **M\u00e9tricas balanceadas**: F1-Macro m\u00e1s importante que accuracy\n",
    "\n",
    "### \ud83d\ude80 Pr\u00f3ximos Pasos:\n",
    "1. **Notebook 07**: Interpretaci\u00f3n con SHAP values\n",
    "2. **Notebook 08**: Aplicaci\u00f3n web con Streamlit\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}